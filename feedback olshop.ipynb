{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Ulasan Online Shop\n",
    "Berikut ini proses untuk mengelompokkan Ulasan (Feed Back) di Online Shop berdasarkan Label tingkat kepuasan konsumen dengan\n",
    "menggunakan Algoritma Knn.\n",
    "\n",
    "### Label Tingkat Kepuasan\n",
    "    => 0 = Tidak  Puas\n",
    "    => 1 = Kurang Puas\n",
    "    => 2 = Cukup  Puas\n",
    "    => 3 = Sangat Puas\n",
    "\n",
    "### Ref:\n",
    "   - https://github.com/andrepamungkas/klasifikasi-sms-knn\n",
    "   - https://bukalapak.com\n",
    "   - https://tokopedia.com\n",
    "   - https://shoope.co.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inisialisasi library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# sklearn - machine learning library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# numpy - scientific computing library\n",
    "import numpy as np\n",
    "\n",
    "# pandas - python data analysis library\n",
    "import pandas as pd\n",
    "\n",
    "# sastrawi - stemming library (bahasa indonesia)\n",
    "#pip install Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# tqdm - progress bar library\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Membersihkan dokumen dengan cara:\n",
    "1. Menghilangkan kata yang tidak penting\n",
    "2. Menghilangkan tanda baca\n",
    "3. Mengubah kata ke bentuk dasar\n",
    "4. Menghilangkan angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file yang berisi kata-kata tidak penting\n",
    "data_stopword = json.load(open('stopwords-id.json','r'))\n",
    "\n",
    "# menjadikan array stopword menjadi unordered collection (set())\n",
    "# agar dapat dilakukan operasi matematis seperti union, intersection, symmetric difference\n",
    "stopword = set(data_stopword)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# method untuk cleaning dokumen\n",
    "def clean(doc):\n",
    "    # menghilangkan kata tidak penting\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stopword])\n",
    "    # menghilangkan tanda baca\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in punctuation)\n",
    "    # menjadikan ke kata dasar\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    normalized = stemmer.stem(punc_free)\n",
    "    # menghilangkan angka\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    # membuat satu dokumen menjadi array berisi tiap kata\n",
    "    y = processed.split()\n",
    "    return y\n",
    "\n",
    "# method untuk cleaning dokumen berupa array\n",
    "def clean_with_loop(arr):\n",
    "    hasil = []\n",
    "    progress = tqdm(arr)\n",
    "    for item in progress:\n",
    "        progress.set_description(\"Membersihkan dokumen\")\n",
    "        cleaned = clean(item)\n",
    "        cleaned = ' '.join(cleaned)\n",
    "        hasil.append(cleaned)\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Komentar  Label\n",
      "0         Lama pengiriman. Chat lama tidak si respon      0\n",
      "1                   Kecepatan pengiriman tidak baik.      0\n",
      "2  Barang Belum saya Terima gak tau tuh kondisi b...      0\n",
      "3  Kualitas produk tidak baik. Kecepatan pengirim...      0\n",
      "4  Pengiriman Super Duperr LAMAA!!! Pas ditanya a...      0\n",
      "Jumlah Komentar:  300\n",
      "Jumlah Label:  300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Membersihkan dokumen: 100%|██████████████████████████████████████████████████████████| 300/300 [02:44<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# import dataset olshop\n",
    "olshop_csv = pd.read_csv('dataset_olshop3.csv')\n",
    "print(olshop_csv.head())\n",
    "\n",
    "# mengambil hanya kolom Teks olshop dan disimpan di variabel olshop (yang siap dibersihkan)\n",
    "olshop = []\n",
    "for index, row in olshop_csv.iterrows():\n",
    "    olshop.append(row[\"Komentar\"])\n",
    "print(\"Jumlah Komentar: \", len(olshop))\n",
    "\n",
    "# mengambil hanya kolom label dalam variabel y_train\n",
    "y_train = []\n",
    "for index, row in olshop_csv.iterrows():\n",
    "    y_train.append(row[\"Label\"])\n",
    "print(\"Jumlah Label: \", len(y_train))\n",
    "\n",
    "# membersihkan dokumen olshop\n",
    "olshop_bersih = clean_with_loop(olshop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membentuk TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 435)\t0.6340464614196564\n",
      "  (0, 392)\t0.223453997314607\n",
      "  (0, 158)\t0.4107604146663474\n",
      "  (0, 833)\t0.22758319973940824\n",
      "  (0, 748)\t0.49782062895428575\n",
      "  (0, 673)\t0.2823292159384112\n",
      "  (1, 392)\t0.5179369945820095\n",
      "  (1, 833)\t0.5275079430529434\n",
      "  (1, 153)\t0.6734067416201059\n",
      "  (2, 65)\t0.2901182540228691\n",
      "  (2, 820)\t0.13338051480298993\n",
      "  (2, 251)\t0.15332971717384053\n",
      "  (2, 806)\t0.17560149845903106\n",
      "  (2, 866)\t0.2450703738925918\n",
      "  (2, 407)\t0.18857856098172784\n",
      "  (2, 387)\t0.21682446743715986\n",
      "  (2, 799)\t0.21682446743715986\n",
      "  (2, 798)\t0.2450703738925918\n",
      "  (2, 514)\t0.15786218729401252\n",
      "  (2, 620)\t0.15123950367273206\n",
      "  (2, 741)\t0.10320904246101767\n",
      "  (2, 284)\t0.20030167136185453\n",
      "  (2, 458)\t0.415462633167192\n",
      "  (2, 115)\t0.21682446743715986\n",
      "  (2, 770)\t0.2450703738925918\n",
      "  :\t:\n",
      "  (296, 478)\t0.2601050751751309\n",
      "  (296, 781)\t0.29067696945664856\n",
      "  (296, 21)\t0.3063930841469272\n",
      "  (296, 216)\t0.3285437037097858\n",
      "  (296, 76)\t0.3285437037097858\n",
      "  (296, 747)\t0.3285437037097858\n",
      "  (296, 762)\t0.3285437037097858\n",
      "  (297, 165)\t0.5142926323597505\n",
      "  (297, 447)\t0.5468679019425253\n",
      "  (297, 483)\t0.6606349870582537\n",
      "  (298, 65)\t0.10584458387032214\n",
      "  (298, 43)\t0.17948827329083478\n",
      "  (298, 375)\t0.3335263870260834\n",
      "  (298, 651)\t0.3335263870260834\n",
      "  (298, 690)\t0.3335263870260834\n",
      "  (298, 670)\t0.3335263870260834\n",
      "  (298, 3)\t0.3576386026583617\n",
      "  (298, 715)\t0.3576386026583617\n",
      "  (298, 466)\t0.3576386026583617\n",
      "  (298, 682)\t0.3576386026583617\n",
      "  (299, 646)\t0.3794555152585291\n",
      "  (299, 727)\t0.3794555152585291\n",
      "  (299, 483)\t0.4583951417180588\n",
      "  (299, 506)\t0.48317932270829705\n",
      "  (299, 267)\t0.5181106638896757\n"
     ]
    }
   ],
   "source": [
    "# pembentukan vektor tf-idf untuk pembobotan kata\n",
    "vectorizer = TfidfVectorizer(stop_words=data_stopword)\n",
    "x_train = vectorizer.fit_transform(olshop_bersih)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note!\n",
    "\n",
    "Kalau error `IOPub data rate exceeded`\n",
    "1. Buka **Anaconda Prompt**\n",
    "2. Jalankan perintah `jupyter notebook --generate-config` untuk generate file config\n",
    "3. Buka file config yang lokasinya ditampilkan setelah step 2 dieksekusi\n",
    "4. Cari `c.NotebookApp.iopub_data_rate_limit`\n",
    "5. Hapus `#` di depan dan ubah nilainya `10000000` (tambah 0 satu kali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pengelompokan dokumen dengan knn (k=5)\n",
    "# penghitungan jarak dengan euclidean distance\n",
    "# dokumentasi: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "modelknn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "modelknn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Membersihkan dokumen: 100%|██████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lama sampai chat respon lama :\n",
      "- Rating: Tidak Puas\n",
      "\n",
      "barang terima baik kualitas nya tidak sesuai kira :\n",
      "- Rating: Kurang Puas\n",
      "\n",
      "kualitas produk standar harga produk standar :\n",
      "- Rating: Cukup Puas\n",
      "\n",
      "alhamdulillah barang jalan baik terima kasih :\n",
      "- Rating: Sangat Puas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kalimat_tes = [\"Lama sampainya chat respon lama\",\n",
    "               \"barang diterima dengan baik, tetapi kualitas nya tidak sesuai dengan perkiraan saya\",\n",
    "               \"Kualitas produk standar. Harga produk standar.\",\n",
    "               \"alhamdulillah barang berjalan dengan baik,, terima kasih\"\n",
    "              ]\n",
    "\n",
    "# membersihkan dokumen pengujian\n",
    "kalimat_tes_bersih = clean_with_loop(kalimat_tes)\n",
    "\n",
    "# definisikan nama label\n",
    "nama_label = [\"Tidak\",\"Kurang\",\"Cukup\" ,\"Sangat\"]\n",
    "\n",
    "# loop untuk prediksi kelompok\n",
    "for teks in kalimat_tes_bersih:\n",
    "    arr_teks = []\n",
    "    arr_teks.append(teks)\n",
    "    vektor = vectorizer.transform(arr_teks)\n",
    "    prediksi_label_knn = modelknn.predict(vektor)\n",
    "    print(teks, \":\\n\" + \"- Rating: \" + nama_label[np.int(prediksi_label_knn)]+ \" Puas\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
